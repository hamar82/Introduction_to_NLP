{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqkfV-yhXn7a"
   },
   "source": [
    "# Урок 10. Машинный перевод. Модель seq2seq и механизм внимания\n",
    "\n",
    "Разобраться с моделью перевода (без механизма внимания) как она устроена, запустить для перевода с русского на английский (при желании можно взять другие пары языков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "70nADwSiX7nt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAXkIKgdX_R9",
    "outputId": "080738a6-25de-4b8b-e7b4-6ec3382d912c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-09-15 09:21:11--  http://www.manythings.org/anki/rus-eng.zip\n",
      "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
      "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15011848 (14M) [application/zip]\n",
      "Saving to: ‘rus-eng.zip’\n",
      "\n",
      "rus-eng.zip         100%[===================>]  14.32M  6.18MB/s    in 2.3s    \n",
      "\n",
      "2022-09-15 09:21:14 (6.18 MB/s) - ‘rus-eng.zip’ saved [15011848/15011848]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.manythings.org/anki/rus-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSYKlAlGYIGY",
    "outputId": "e57e5cc6-e335-41cd-a115-fd242eea72b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  rus-eng.zip\n",
      "  inflating: rus-eng/rus.txt         \n",
      "  inflating: rus-eng/_about.txt      \n"
     ]
    }
   ],
   "source": [
    "!mkdir rus-eng\n",
    "!unzip rus-eng.zip -d rus-eng/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0jQGHb9YM5g",
    "outputId": "54cdbc28-1582-4231-a31e-864738695bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 72M\n",
      "drwxr-xr-x 2 root root 4.0K Sep 15 09:21 .\n",
      "drwxr-xr-x 1 root root 4.0K Sep 15 09:21 ..\n",
      "-rw-r--r-- 1 root root 1.5K Sep  6 03:10 _about.txt\n",
      "-rw-r--r-- 1 root root  72M Sep  6 03:10 rus.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /content/rus-eng/ -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "T10vFJvjYUlg"
   },
   "outputs": [],
   "source": [
    "# Download the file\n",
    "path_to_file = \"/content/rus-eng/rus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VZNoCtMNYXUh"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "  w = w.lower().strip()\n",
    "\n",
    "  # creating a space between a word and the punctuation following it\n",
    "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "  w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
    "  w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "  w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n",
    "\n",
    "  w = w.strip()\n",
    "\n",
    "  # adding a start and an end token to the sentence\n",
    "  # so that the model know when to start and stop predicting.\n",
    "  w = '<start> ' + w + ' <end>'\n",
    "  return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "uEqwZNMQYea_",
    "outputId": "4913921f-0f94-4da4-f20a-039e09da4197"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"<start> i can't go . <end>\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_sentence(\"I can't go.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "j0vMFnJDYhcn"
   },
   "outputs": [],
   "source": [
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENG, RUS]\n",
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
    "\n",
    "  return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOh51gHUaIkF",
    "outputId": "6a7a5174-3ae8-4b77-b4d9-db6f5594ab2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> smile . <end>\n",
      "<start> улыбнитесь . <end>\n"
     ]
    }
   ],
   "source": [
    "en, ru = create_dataset(path_to_file, None)\n",
    "print(en[77])\n",
    "print(ru[77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6a6NAcdanC5",
    "outputId": "1f32bdf3-9503-4525-e585-a7cde0a87844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> run ! <end>\n",
      "<start> бегите ! <end>\n"
     ]
    }
   ],
   "source": [
    "print(en[10])\n",
    "print(ru[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ojNzNbwUar_r"
   },
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "PY6qPkTtaxWJ"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "  # creating cleaned input, output pairs\n",
    "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFlYzZpea4zk",
    "outputId": "052e1b37-356d-4480-bc2e-3441e17d0e5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(451436, 451436)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en), len(ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KSPlX3bXbNqG"
   },
   "outputs": [],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 100000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5kAy7MKbYGd",
    "outputId": "446342a3-f126-4c35-8bd7-0a7a84dd35bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000 80000 20000 20000\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Yz6lxKBebiip"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EX5M0dC4cHOB",
    "outputId": "0142ca15-6389-4a95-c494-80b1722591cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "8 ----> это\n",
      "36 ----> было\n",
      "45 ----> бы\n",
      "732 ----> глупо\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "18 ----> that\n",
      "190 ----> would\n",
      "33 ----> be\n",
      "286 ----> stupid\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOBR8wYucoKt"
   },
   "source": [
    "## Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CwsMIgODcJjS"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 1024\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 300\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LA2obp7dYU_",
    "outputId": "85f4deb6-ece5-43b8-aba0-9e468db02928"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1024, 15]), TensorShape([1024, 11]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "AEfwgNsLdiue"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=False,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nR7mM6xGeNUD",
    "outputId": "9a91a3f6-b769-4175-f0fb-5f5214d9ad32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Hidden state shape: (batch size, units) (1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aNlXVuSeTCG"
   },
   "source": [
    "## Decoder without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "E2etAnhSeW9o"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dYtIT1eFebex"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "decoder_sample_x, decoder_sample_h = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybHgSa0keRVn",
    "outputId": "901c29fd-0fce-442c-b54f-4a2d03f66714"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1024, 7335])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sample_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LEExyx3PewRF",
    "outputId": "9cf6ea44-4f3e-4950-a588-970524a00256"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1024, 1024])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_sample_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "otgPp7zQeyI7"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "pDIJYKI6e34j"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_nmt_checkpoints'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "LIrAYhnTfW_q"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4j24A3_tfeLa",
    "outputId": "99c5b922-66f6-458a-ee67-ffa11d168251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.6222\n",
      "Epoch 1 Batch 50 Loss 2.0955\n",
      "Epoch 1 Loss 2.3069\n",
      "Time taken for 1 epoch 34.88617563247681 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.9523\n",
      "Epoch 2 Batch 50 Loss 1.8393\n",
      "Epoch 2 Loss 1.8640\n",
      "Time taken for 1 epoch 23.375584363937378 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.7376\n",
      "Epoch 3 Batch 50 Loss 1.6451\n",
      "Epoch 3 Loss 1.6575\n",
      "Time taken for 1 epoch 23.828977584838867 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.5228\n",
      "Epoch 4 Batch 50 Loss 1.4469\n",
      "Epoch 4 Loss 1.4608\n",
      "Time taken for 1 epoch 25.001121520996094 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.3700\n",
      "Epoch 5 Batch 50 Loss 1.2977\n",
      "Epoch 5 Loss 1.3096\n",
      "Time taken for 1 epoch 24.567402362823486 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.2072\n",
      "Epoch 6 Batch 50 Loss 1.1958\n",
      "Epoch 6 Loss 1.1760\n",
      "Time taken for 1 epoch 24.88222050666809 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.1067\n",
      "Epoch 7 Batch 50 Loss 1.0344\n",
      "Epoch 7 Loss 1.0512\n",
      "Time taken for 1 epoch 25.182317972183228 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.9444\n",
      "Epoch 8 Batch 50 Loss 0.9116\n",
      "Epoch 8 Loss 0.9263\n",
      "Time taken for 1 epoch 26.099363803863525 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.8256\n",
      "Epoch 9 Batch 50 Loss 0.7988\n",
      "Epoch 9 Loss 0.8095\n",
      "Time taken for 1 epoch 25.422332286834717 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.7159\n",
      "Epoch 10 Batch 50 Loss 0.7087\n",
      "Epoch 10 Loss 0.6997\n",
      "Time taken for 1 epoch 25.507819652557373 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.6262\n",
      "Epoch 11 Batch 50 Loss 0.5988\n",
      "Epoch 11 Loss 0.5936\n",
      "Time taken for 1 epoch 25.559205532073975 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.4831\n",
      "Epoch 12 Batch 50 Loss 0.4999\n",
      "Epoch 12 Loss 0.4963\n",
      "Time taken for 1 epoch 26.159672498703003 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.4046\n",
      "Epoch 13 Batch 50 Loss 0.4107\n",
      "Epoch 13 Loss 0.4094\n",
      "Time taken for 1 epoch 25.55348539352417 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.3444\n",
      "Epoch 14 Batch 50 Loss 0.3461\n",
      "Epoch 14 Loss 0.3352\n",
      "Time taken for 1 epoch 25.65266728401184 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.2685\n",
      "Epoch 15 Batch 50 Loss 0.2651\n",
      "Epoch 15 Loss 0.2750\n",
      "Time taken for 1 epoch 25.709823608398438 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.2146\n",
      "Epoch 16 Batch 50 Loss 0.2479\n",
      "Epoch 16 Loss 0.2262\n",
      "Time taken for 1 epoch 26.184712409973145 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.1768\n",
      "Epoch 17 Batch 50 Loss 0.1863\n",
      "Epoch 17 Loss 0.1876\n",
      "Time taken for 1 epoch 25.553616046905518 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.1499\n",
      "Epoch 18 Batch 50 Loss 0.1551\n",
      "Epoch 18 Loss 0.1585\n",
      "Time taken for 1 epoch 25.752759218215942 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.1191\n",
      "Epoch 19 Batch 50 Loss 0.1322\n",
      "Epoch 19 Loss 0.1351\n",
      "Time taken for 1 epoch 25.63994073867798 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.1112\n",
      "Epoch 20 Batch 50 Loss 0.1184\n",
      "Epoch 20 Loss 0.1174\n",
      "Time taken for 1 epoch 26.147709131240845 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0949\n",
      "Epoch 21 Batch 50 Loss 0.1070\n",
      "Epoch 21 Loss 0.1025\n",
      "Time taken for 1 epoch 25.605392932891846 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0854\n",
      "Epoch 22 Batch 50 Loss 0.0979\n",
      "Epoch 22 Loss 0.0910\n",
      "Time taken for 1 epoch 25.70555567741394 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0755\n",
      "Epoch 23 Batch 50 Loss 0.0805\n",
      "Epoch 23 Loss 0.0821\n",
      "Time taken for 1 epoch 25.636309385299683 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0663\n",
      "Epoch 24 Batch 50 Loss 0.0770\n",
      "Epoch 24 Loss 0.0741\n",
      "Time taken for 1 epoch 26.339576721191406 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0636\n",
      "Epoch 25 Batch 50 Loss 0.0676\n",
      "Epoch 25 Loss 0.0678\n",
      "Time taken for 1 epoch 25.657983541488647 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0534\n",
      "Epoch 26 Batch 50 Loss 0.0661\n",
      "Epoch 26 Loss 0.0632\n",
      "Time taken for 1 epoch 25.476704597473145 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0510\n",
      "Epoch 27 Batch 50 Loss 0.0624\n",
      "Epoch 27 Loss 0.0586\n",
      "Time taken for 1 epoch 25.60182762145996 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0484\n",
      "Epoch 28 Batch 50 Loss 0.0578\n",
      "Epoch 28 Loss 0.0551\n",
      "Time taken for 1 epoch 26.366957187652588 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0474\n",
      "Epoch 29 Batch 50 Loss 0.0529\n",
      "Epoch 29 Loss 0.0519\n",
      "Time taken for 1 epoch 25.685383319854736 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0460\n",
      "Epoch 30 Batch 50 Loss 0.0493\n",
      "Epoch 30 Loss 0.0497\n",
      "Time taken for 1 epoch 25.590020418167114 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0404\n",
      "Epoch 31 Batch 50 Loss 0.0523\n",
      "Epoch 31 Loss 0.0474\n",
      "Time taken for 1 epoch 25.627496004104614 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0393\n",
      "Epoch 32 Batch 50 Loss 0.0460\n",
      "Epoch 32 Loss 0.0454\n",
      "Time taken for 1 epoch 26.295462131500244 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0364\n",
      "Epoch 33 Batch 50 Loss 0.0477\n",
      "Epoch 33 Loss 0.0443\n",
      "Time taken for 1 epoch 25.58573007583618 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0366\n",
      "Epoch 34 Batch 50 Loss 0.0464\n",
      "Epoch 34 Loss 0.0429\n",
      "Time taken for 1 epoch 25.63146734237671 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0350\n",
      "Epoch 35 Batch 50 Loss 0.0456\n",
      "Epoch 35 Loss 0.0417\n",
      "Time taken for 1 epoch 25.64186120033264 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0311\n",
      "Epoch 36 Batch 50 Loss 0.0432\n",
      "Epoch 36 Loss 0.0407\n",
      "Time taken for 1 epoch 26.38408350944519 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0336\n",
      "Epoch 37 Batch 50 Loss 0.0392\n",
      "Epoch 37 Loss 0.0398\n",
      "Time taken for 1 epoch 25.632760763168335 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0343\n",
      "Epoch 38 Batch 50 Loss 0.0378\n",
      "Epoch 38 Loss 0.0393\n",
      "Time taken for 1 epoch 25.627581357955933 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0328\n",
      "Epoch 39 Batch 50 Loss 0.0409\n",
      "Epoch 39 Loss 0.0388\n",
      "Time taken for 1 epoch 25.585020065307617 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0290\n",
      "Epoch 40 Batch 50 Loss 0.0405\n",
      "Epoch 40 Loss 0.0378\n",
      "Time taken for 1 epoch 26.21848464012146 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.0293\n",
      "Epoch 41 Batch 50 Loss 0.0425\n",
      "Epoch 41 Loss 0.0377\n",
      "Time taken for 1 epoch 25.618500232696533 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.0330\n",
      "Epoch 42 Batch 50 Loss 0.0387\n",
      "Epoch 42 Loss 0.0374\n",
      "Time taken for 1 epoch 25.63615345954895 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.0314\n",
      "Epoch 43 Batch 50 Loss 0.0408\n",
      "Epoch 43 Loss 0.0368\n",
      "Time taken for 1 epoch 25.60861825942993 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.0316\n",
      "Epoch 44 Batch 50 Loss 0.0399\n",
      "Epoch 44 Loss 0.0365\n",
      "Time taken for 1 epoch 26.342302083969116 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.0315\n",
      "Epoch 45 Batch 50 Loss 0.0392\n",
      "Epoch 45 Loss 0.0362\n",
      "Time taken for 1 epoch 25.651068210601807 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.0289\n",
      "Epoch 46 Batch 50 Loss 0.0395\n",
      "Epoch 46 Loss 0.0356\n",
      "Time taken for 1 epoch 25.6711368560791 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.0323\n",
      "Epoch 47 Batch 50 Loss 0.0351\n",
      "Epoch 47 Loss 0.0357\n",
      "Time taken for 1 epoch 25.704825162887573 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.0292\n",
      "Epoch 48 Batch 50 Loss 0.0388\n",
      "Epoch 48 Loss 0.0354\n",
      "Time taken for 1 epoch 26.342501878738403 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.0274\n",
      "Epoch 49 Batch 50 Loss 0.0377\n",
      "Epoch 49 Loss 0.0350\n",
      "Time taken for 1 epoch 25.57885241508484 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.0255\n",
      "Epoch 50 Batch 50 Loss 0.0370\n",
      "Epoch 50 Loss 0.0348\n",
      "Time taken for 1 epoch 25.46561074256897 sec\n",
      "\n",
      "Epoch 51 Batch 0 Loss 0.0262\n",
      "Epoch 51 Batch 50 Loss 0.0324\n",
      "Epoch 51 Loss 0.0348\n",
      "Time taken for 1 epoch 25.617231607437134 sec\n",
      "\n",
      "Epoch 52 Batch 0 Loss 0.0274\n",
      "Epoch 52 Batch 50 Loss 0.0349\n",
      "Epoch 52 Loss 0.0346\n",
      "Time taken for 1 epoch 26.304725646972656 sec\n",
      "\n",
      "Epoch 53 Batch 0 Loss 0.0264\n",
      "Epoch 53 Batch 50 Loss 0.0407\n",
      "Epoch 53 Loss 0.0345\n",
      "Time taken for 1 epoch 25.74026131629944 sec\n",
      "\n",
      "Epoch 54 Batch 0 Loss 0.0304\n",
      "Epoch 54 Batch 50 Loss 0.0298\n",
      "Epoch 54 Loss 0.0342\n",
      "Time taken for 1 epoch 25.563003540039062 sec\n",
      "\n",
      "Epoch 55 Batch 0 Loss 0.0286\n",
      "Epoch 55 Batch 50 Loss 0.0397\n",
      "Epoch 55 Loss 0.0344\n",
      "Time taken for 1 epoch 25.599278450012207 sec\n",
      "\n",
      "Epoch 56 Batch 0 Loss 0.0253\n",
      "Epoch 56 Batch 50 Loss 0.0375\n",
      "Epoch 56 Loss 0.0340\n",
      "Time taken for 1 epoch 26.181668043136597 sec\n",
      "\n",
      "Epoch 57 Batch 0 Loss 0.0273\n",
      "Epoch 57 Batch 50 Loss 0.0392\n",
      "Epoch 57 Loss 0.0339\n",
      "Time taken for 1 epoch 25.626551151275635 sec\n",
      "\n",
      "Epoch 58 Batch 0 Loss 0.0269\n",
      "Epoch 58 Batch 50 Loss 0.0354\n",
      "Epoch 58 Loss 0.0338\n",
      "Time taken for 1 epoch 25.560896396636963 sec\n",
      "\n",
      "Epoch 59 Batch 0 Loss 0.0257\n",
      "Epoch 59 Batch 50 Loss 0.0375\n",
      "Epoch 59 Loss 0.0339\n",
      "Time taken for 1 epoch 25.60338306427002 sec\n",
      "\n",
      "Epoch 60 Batch 0 Loss 0.0281\n",
      "Epoch 60 Batch 50 Loss 0.0396\n",
      "Epoch 60 Loss 0.0337\n",
      "Time taken for 1 epoch 26.253326654434204 sec\n",
      "\n",
      "Epoch 61 Batch 0 Loss 0.0278\n",
      "Epoch 61 Batch 50 Loss 0.0364\n",
      "Epoch 61 Loss 0.0339\n",
      "Time taken for 1 epoch 25.799936056137085 sec\n",
      "\n",
      "Epoch 62 Batch 0 Loss 0.0285\n",
      "Epoch 62 Batch 50 Loss 0.0376\n",
      "Epoch 62 Loss 0.0335\n",
      "Time taken for 1 epoch 25.636786460876465 sec\n",
      "\n",
      "Epoch 63 Batch 0 Loss 0.0305\n",
      "Epoch 63 Batch 50 Loss 0.0372\n",
      "Epoch 63 Loss 0.0334\n",
      "Time taken for 1 epoch 25.577774047851562 sec\n",
      "\n",
      "Epoch 64 Batch 0 Loss 0.0239\n",
      "Epoch 64 Batch 50 Loss 0.0351\n",
      "Epoch 64 Loss 0.0333\n",
      "Time taken for 1 epoch 26.2912700176239 sec\n",
      "\n",
      "Epoch 65 Batch 0 Loss 0.0252\n",
      "Epoch 65 Batch 50 Loss 0.0413\n",
      "Epoch 65 Loss 0.0332\n",
      "Time taken for 1 epoch 25.708322048187256 sec\n",
      "\n",
      "Epoch 66 Batch 0 Loss 0.0255\n",
      "Epoch 66 Batch 50 Loss 0.0372\n",
      "Epoch 66 Loss 0.0335\n",
      "Time taken for 1 epoch 25.755842447280884 sec\n",
      "\n",
      "Epoch 67 Batch 0 Loss 0.0259\n",
      "Epoch 67 Batch 50 Loss 0.0377\n",
      "Epoch 67 Loss 0.0333\n",
      "Time taken for 1 epoch 25.689038515090942 sec\n",
      "\n",
      "Epoch 68 Batch 0 Loss 0.0298\n",
      "Epoch 68 Batch 50 Loss 0.0336\n",
      "Epoch 68 Loss 0.0328\n",
      "Time taken for 1 epoch 26.28704023361206 sec\n",
      "\n",
      "Epoch 69 Batch 0 Loss 0.0266\n",
      "Epoch 69 Batch 50 Loss 0.0371\n",
      "Epoch 69 Loss 0.0329\n",
      "Time taken for 1 epoch 25.58220362663269 sec\n",
      "\n",
      "Epoch 70 Batch 0 Loss 0.0276\n",
      "Epoch 70 Batch 50 Loss 0.0348\n",
      "Epoch 70 Loss 0.0325\n",
      "Time taken for 1 epoch 25.619285821914673 sec\n",
      "\n",
      "Epoch 71 Batch 0 Loss 0.0264\n",
      "Epoch 71 Batch 50 Loss 0.0360\n",
      "Epoch 71 Loss 0.0327\n",
      "Time taken for 1 epoch 25.586806774139404 sec\n",
      "\n",
      "Epoch 72 Batch 0 Loss 0.0225\n",
      "Epoch 72 Batch 50 Loss 0.0366\n",
      "Epoch 72 Loss 0.0324\n",
      "Time taken for 1 epoch 26.23323678970337 sec\n",
      "\n",
      "Epoch 73 Batch 0 Loss 0.0251\n",
      "Epoch 73 Batch 50 Loss 0.0332\n",
      "Epoch 73 Loss 0.0322\n",
      "Time taken for 1 epoch 25.61537194252014 sec\n",
      "\n",
      "Epoch 74 Batch 0 Loss 0.0277\n",
      "Epoch 74 Batch 50 Loss 0.0368\n",
      "Epoch 74 Loss 0.0323\n",
      "Time taken for 1 epoch 25.66690731048584 sec\n",
      "\n",
      "Epoch 75 Batch 0 Loss 0.0230\n",
      "Epoch 75 Batch 50 Loss 0.0361\n",
      "Epoch 75 Loss 0.0322\n",
      "Time taken for 1 epoch 25.66971206665039 sec\n",
      "\n",
      "Epoch 76 Batch 0 Loss 0.0251\n",
      "Epoch 76 Batch 50 Loss 0.0346\n",
      "Epoch 76 Loss 0.0322\n",
      "Time taken for 1 epoch 26.362184047698975 sec\n",
      "\n",
      "Epoch 77 Batch 0 Loss 0.0227\n",
      "Epoch 77 Batch 50 Loss 0.0332\n",
      "Epoch 77 Loss 0.0315\n",
      "Time taken for 1 epoch 25.708810091018677 sec\n",
      "\n",
      "Epoch 78 Batch 0 Loss 0.0277\n",
      "Epoch 78 Batch 50 Loss 0.0336\n",
      "Epoch 78 Loss 0.0317\n",
      "Time taken for 1 epoch 25.67510962486267 sec\n",
      "\n",
      "Epoch 79 Batch 0 Loss 0.0241\n",
      "Epoch 79 Batch 50 Loss 0.0354\n",
      "Epoch 79 Loss 0.0320\n",
      "Time taken for 1 epoch 25.701838493347168 sec\n",
      "\n",
      "Epoch 80 Batch 0 Loss 0.0211\n",
      "Epoch 80 Batch 50 Loss 0.0352\n",
      "Epoch 80 Loss 0.0316\n",
      "Time taken for 1 epoch 26.35790467262268 sec\n",
      "\n",
      "Epoch 81 Batch 0 Loss 0.0267\n",
      "Epoch 81 Batch 50 Loss 0.0349\n",
      "Epoch 81 Loss 0.0315\n",
      "Time taken for 1 epoch 25.71410822868347 sec\n",
      "\n",
      "Epoch 82 Batch 0 Loss 0.0234\n",
      "Epoch 82 Batch 50 Loss 0.0322\n",
      "Epoch 82 Loss 0.0313\n",
      "Time taken for 1 epoch 25.651670455932617 sec\n",
      "\n",
      "Epoch 83 Batch 0 Loss 0.0260\n",
      "Epoch 83 Batch 50 Loss 0.0313\n",
      "Epoch 83 Loss 0.0311\n",
      "Time taken for 1 epoch 25.654338598251343 sec\n",
      "\n",
      "Epoch 84 Batch 0 Loss 0.0238\n",
      "Epoch 84 Batch 50 Loss 0.0361\n",
      "Epoch 84 Loss 0.0313\n",
      "Time taken for 1 epoch 26.23732352256775 sec\n",
      "\n",
      "Epoch 85 Batch 0 Loss 0.0230\n",
      "Epoch 85 Batch 50 Loss 0.0347\n",
      "Epoch 85 Loss 0.0313\n",
      "Time taken for 1 epoch 25.620043992996216 sec\n",
      "\n",
      "Epoch 86 Batch 0 Loss 0.0259\n",
      "Epoch 86 Batch 50 Loss 0.0331\n",
      "Epoch 86 Loss 0.0309\n",
      "Time taken for 1 epoch 25.670137405395508 sec\n",
      "\n",
      "Epoch 87 Batch 0 Loss 0.0248\n",
      "Epoch 87 Batch 50 Loss 0.0291\n",
      "Epoch 87 Loss 0.0311\n",
      "Time taken for 1 epoch 25.715131521224976 sec\n",
      "\n",
      "Epoch 88 Batch 0 Loss 0.0227\n",
      "Epoch 88 Batch 50 Loss 0.0370\n",
      "Epoch 88 Loss 0.0308\n",
      "Time taken for 1 epoch 26.31400990486145 sec\n",
      "\n",
      "Epoch 89 Batch 0 Loss 0.0244\n",
      "Epoch 89 Batch 50 Loss 0.0314\n",
      "Epoch 89 Loss 0.0307\n",
      "Time taken for 1 epoch 25.716720819473267 sec\n",
      "\n",
      "Epoch 90 Batch 0 Loss 0.0234\n",
      "Epoch 90 Batch 50 Loss 0.0316\n",
      "Epoch 90 Loss 0.0309\n",
      "Time taken for 1 epoch 25.70639157295227 sec\n",
      "\n",
      "Epoch 91 Batch 0 Loss 0.0238\n",
      "Epoch 91 Batch 50 Loss 0.0355\n",
      "Epoch 91 Loss 0.0305\n",
      "Time taken for 1 epoch 25.740970134735107 sec\n",
      "\n",
      "Epoch 92 Batch 0 Loss 0.0230\n",
      "Epoch 92 Batch 50 Loss 0.0330\n",
      "Epoch 92 Loss 0.0306\n",
      "Time taken for 1 epoch 26.331302642822266 sec\n",
      "\n",
      "Epoch 93 Batch 0 Loss 0.0201\n",
      "Epoch 93 Batch 50 Loss 0.0285\n",
      "Epoch 93 Loss 0.0305\n",
      "Time taken for 1 epoch 25.740724086761475 sec\n",
      "\n",
      "Epoch 94 Batch 0 Loss 0.0192\n",
      "Epoch 94 Batch 50 Loss 0.0345\n",
      "Epoch 94 Loss 0.0305\n",
      "Time taken for 1 epoch 25.732238054275513 sec\n",
      "\n",
      "Epoch 95 Batch 0 Loss 0.0194\n",
      "Epoch 95 Batch 50 Loss 0.0319\n",
      "Epoch 95 Loss 0.0302\n",
      "Time taken for 1 epoch 25.6954083442688 sec\n",
      "\n",
      "Epoch 96 Batch 0 Loss 0.0248\n",
      "Epoch 96 Batch 50 Loss 0.0328\n",
      "Epoch 96 Loss 0.0302\n",
      "Time taken for 1 epoch 26.380839824676514 sec\n",
      "\n",
      "Epoch 97 Batch 0 Loss 0.0206\n",
      "Epoch 97 Batch 50 Loss 0.0341\n",
      "Epoch 97 Loss 0.0300\n",
      "Time taken for 1 epoch 25.64894676208496 sec\n",
      "\n",
      "Epoch 98 Batch 0 Loss 0.0246\n",
      "Epoch 98 Batch 50 Loss 0.0303\n",
      "Epoch 98 Loss 0.0300\n",
      "Time taken for 1 epoch 25.6932532787323 sec\n",
      "\n",
      "Epoch 99 Batch 0 Loss 0.0218\n",
      "Epoch 99 Batch 50 Loss 0.0293\n",
      "Epoch 99 Loss 0.0299\n",
      "Time taken for 1 epoch 25.681028127670288 sec\n",
      "\n",
      "Epoch 100 Batch 0 Loss 0.0239\n",
      "Epoch 100 Batch 50 Loss 0.0337\n",
      "Epoch 100 Loss 0.0302\n",
      "Time taken for 1 epoch 26.374235153198242 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 4 epochs\n",
    "  if (epoch + 1) % 4 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "4l1FAZBhfxul"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result, sentence\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "gW2Bj7Otf2YV"
   },
   "outputs": [],
   "source": [
    "def remove_char(s):\n",
    "    remove_result = s[8 : -6]\n",
    "    return remove_result\n",
    "\n",
    "def remove_char_trans(s):\n",
    "    remove_result_trans = s[0 : -6]\n",
    "    return remove_result_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "28xWkpHOgqFl"
   },
   "outputs": [],
   "source": [
    "final_result = []\n",
    "\n",
    "def translate(sentence):\n",
    "  result, sentence = evaluate(sentence)\n",
    "\n",
    "  sent = (remove_char(sentence))\n",
    "  res = (remove_char_trans(result))\n",
    "  \n",
    "  final_result.append([sent, res])\n",
    "  df = pd.DataFrame(final_result, columns=['текст', 'перевод без внимания'])\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "1KwQHyapgs_I",
    "outputId": "0854059f-bcb9-4c6a-e32c-d182975920e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0d8ddd6b-8de3-4e0d-beac-a45271db5dfc\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>текст</th>\n",
       "      <th>перевод без внимания</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>привет !</td>\n",
       "      <td>hello !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>как дела ?</td>\n",
       "      <td>how are you ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>как тебя зовут ?</td>\n",
       "      <td>how is your name ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>что ты делаешь завтра ?</td>\n",
       "      <td>what are you all tomorrow ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>я собираюсь играть в футбол</td>\n",
       "      <td>i play football .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>если я смогу , я приду играть</td>\n",
       "      <td>if i can come , me ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>когда мы играли в футбол , шел дождь</td>\n",
       "      <td>when did we miss the car ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>в последнее время я поздно ложусь спать</td>\n",
       "      <td>i'm in boston , too .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>когда я ехал мимо станции , у меня слетела шляпа</td>\n",
       "      <td>when did i look very fat ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ж птица гордая , пока не дадут скорость летать...</td>\n",
       "      <td>ok to stay with me .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d8ddd6b-8de3-4e0d-beac-a45271db5dfc')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0d8ddd6b-8de3-4e0d-beac-a45271db5dfc button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0d8ddd6b-8de3-4e0d-beac-a45271db5dfc');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               текст  \\\n",
       "0                                           привет !   \n",
       "1                                         как дела ?   \n",
       "2                                   как тебя зовут ?   \n",
       "3                            что ты делаешь завтра ?   \n",
       "4                        я собираюсь играть в футбол   \n",
       "5                      если я смогу , я приду играть   \n",
       "6               когда мы играли в футбол , шел дождь   \n",
       "7            в последнее время я поздно ложусь спать   \n",
       "8   когда я ехал мимо станции , у меня слетела шляпа   \n",
       "9  ж птица гордая , пока не дадут скорость летать...   \n",
       "\n",
       "           перевод без внимания  \n",
       "0                      hello !   \n",
       "1                how are you ?   \n",
       "2           how is your name ?   \n",
       "3  what are you all tomorrow ?   \n",
       "4            i play football .   \n",
       "5         if i can come , me ?   \n",
       "6   when did we miss the car ?   \n",
       "7        i'm in boston , too .   \n",
       "8   when did i look very fat ?   \n",
       "9         ok to stay with me .   "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Привет!')\n",
    "translate('Как дела?')\n",
    "translate('Как тебя зовут?')\n",
    "translate('Что ты делаешь завтра?')\n",
    "translate('Я собираюсь играть в футбол')\n",
    "translate('Если я смогу, я приду играть')\n",
    "translate('Когда мы играли в футбол, шел дождь')\n",
    "translate('В последнее время я поздно ложусь спать')\n",
    "translate('Когда я ехал мимо станции, у меня слетела шляпа')\n",
    "translate('Ёж птица гордая, пока не дадут скорость - летать не станет')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LAitnycnaln"
   },
   "source": [
    "Короткие предложения сеть хоть с ошибками, но переводит. С длинными предложениями сеть не справляется совсем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения рассмотрим модель с механизмом внимания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D--lbaRva1Lr"
   },
   "source": [
    "## Decoder with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VlaMplW4Yipr"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ShEHRLxa9w9",
    "outputId": "a5bd031c-85de-4ea1-ab9f-4465fbd8381e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (1024, 15, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "9MGv4fqtbGsc"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZG_KpckbMQb",
    "outputId": "2869a0b2-3324-4a6a-a575-d66633c300e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (1024, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (1024, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "0rl3fmZmbRDg"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nK2Kuw0BbcIp",
    "outputId": "86743806-2970-4309-ffbd-315b09f0d824"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (1024, 7335)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "0GK2_y2Gbhhx"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "sVGza944bonN"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_attention_checkpoints2'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsvsGHlWbteu",
    "outputId": "7d9e2d9c-0100-47b1-9bc1-61bfc354d412"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.0205\n",
      "Epoch 1 Batch 50 Loss 0.0355\n",
      "Epoch 1 Loss 0.0298\n",
      "Time taken for 1 epoch 25.67899227142334 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0227\n",
      "Epoch 2 Batch 50 Loss 0.0366\n",
      "Epoch 2 Loss 0.0296\n",
      "Time taken for 1 epoch 25.78018617630005 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0205\n",
      "Epoch 3 Batch 50 Loss 0.0346\n",
      "Epoch 3 Loss 0.0297\n",
      "Time taken for 1 epoch 25.78372049331665 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0233\n",
      "Epoch 4 Batch 50 Loss 0.0296\n",
      "Epoch 4 Loss 0.0298\n",
      "Time taken for 1 epoch 25.923246383666992 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0264\n",
      "Epoch 5 Batch 50 Loss 0.0360\n",
      "Epoch 5 Loss 0.0298\n",
      "Time taken for 1 epoch 25.70167064666748 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0209\n",
      "Epoch 6 Batch 50 Loss 0.0326\n",
      "Epoch 6 Loss 0.0294\n",
      "Time taken for 1 epoch 25.616418838500977 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0232\n",
      "Epoch 7 Batch 50 Loss 0.0295\n",
      "Epoch 7 Loss 0.0297\n",
      "Time taken for 1 epoch 25.637518405914307 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0203\n",
      "Epoch 8 Batch 50 Loss 0.0295\n",
      "Epoch 8 Loss 0.0294\n",
      "Time taken for 1 epoch 25.844788789749146 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0270\n",
      "Epoch 9 Batch 50 Loss 0.0309\n",
      "Epoch 9 Loss 0.0293\n",
      "Time taken for 1 epoch 25.606621980667114 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0228\n",
      "Epoch 10 Batch 50 Loss 0.0304\n",
      "Epoch 10 Loss 0.0296\n",
      "Time taken for 1 epoch 25.54135036468506 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0224\n",
      "Epoch 11 Batch 50 Loss 0.0298\n",
      "Epoch 11 Loss 0.0296\n",
      "Time taken for 1 epoch 25.614197731018066 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0196\n",
      "Epoch 12 Batch 50 Loss 0.0315\n",
      "Epoch 12 Loss 0.0293\n",
      "Time taken for 1 epoch 25.94549298286438 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0237\n",
      "Epoch 13 Batch 50 Loss 0.0341\n",
      "Epoch 13 Loss 0.0290\n",
      "Time taken for 1 epoch 25.744643926620483 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0221\n",
      "Epoch 14 Batch 50 Loss 0.0292\n",
      "Epoch 14 Loss 0.0290\n",
      "Time taken for 1 epoch 25.74632716178894 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0210\n",
      "Epoch 15 Batch 50 Loss 0.0319\n",
      "Epoch 15 Loss 0.0288\n",
      "Time taken for 1 epoch 25.73726797103882 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0215\n",
      "Epoch 16 Batch 50 Loss 0.0340\n",
      "Epoch 16 Loss 0.0288\n",
      "Time taken for 1 epoch 25.89968228340149 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0218\n",
      "Epoch 17 Batch 50 Loss 0.0315\n",
      "Epoch 17 Loss 0.0287\n",
      "Time taken for 1 epoch 25.68358325958252 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0205\n",
      "Epoch 18 Batch 50 Loss 0.0343\n",
      "Epoch 18 Loss 0.0286\n",
      "Time taken for 1 epoch 25.691847801208496 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0205\n",
      "Epoch 19 Batch 50 Loss 0.0283\n",
      "Epoch 19 Loss 0.0285\n",
      "Time taken for 1 epoch 25.700678825378418 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0209\n",
      "Epoch 20 Batch 50 Loss 0.0281\n",
      "Epoch 20 Loss 0.0285\n",
      "Time taken for 1 epoch 25.934772968292236 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0208\n",
      "Epoch 21 Batch 50 Loss 0.0315\n",
      "Epoch 21 Loss 0.0281\n",
      "Time taken for 1 epoch 25.709760904312134 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0209\n",
      "Epoch 22 Batch 50 Loss 0.0298\n",
      "Epoch 22 Loss 0.0284\n",
      "Time taken for 1 epoch 25.709553480148315 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0211\n",
      "Epoch 23 Batch 50 Loss 0.0306\n",
      "Epoch 23 Loss 0.0283\n",
      "Time taken for 1 epoch 25.727579832077026 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0238\n",
      "Epoch 24 Batch 50 Loss 0.0320\n",
      "Epoch 24 Loss 0.0283\n",
      "Time taken for 1 epoch 25.949137687683105 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0204\n",
      "Epoch 25 Batch 50 Loss 0.0281\n",
      "Epoch 25 Loss 0.0282\n",
      "Time taken for 1 epoch 25.710141897201538 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0177\n",
      "Epoch 26 Batch 50 Loss 0.0323\n",
      "Epoch 26 Loss 0.0279\n",
      "Time taken for 1 epoch 25.719110012054443 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0230\n",
      "Epoch 27 Batch 50 Loss 0.0339\n",
      "Epoch 27 Loss 0.0280\n",
      "Time taken for 1 epoch 25.738401174545288 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0210\n",
      "Epoch 28 Batch 50 Loss 0.0316\n",
      "Epoch 28 Loss 0.0280\n",
      "Time taken for 1 epoch 25.998031854629517 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0192\n",
      "Epoch 29 Batch 50 Loss 0.0271\n",
      "Epoch 29 Loss 0.0278\n",
      "Time taken for 1 epoch 25.678526639938354 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0211\n",
      "Epoch 30 Batch 50 Loss 0.0310\n",
      "Epoch 30 Loss 0.0276\n",
      "Time taken for 1 epoch 25.703744888305664 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0232\n",
      "Epoch 31 Batch 50 Loss 0.0330\n",
      "Epoch 31 Loss 0.0275\n",
      "Time taken for 1 epoch 25.70653486251831 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0225\n",
      "Epoch 32 Batch 50 Loss 0.0262\n",
      "Epoch 32 Loss 0.0276\n",
      "Time taken for 1 epoch 25.977420568466187 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0214\n",
      "Epoch 33 Batch 50 Loss 0.0297\n",
      "Epoch 33 Loss 0.0276\n",
      "Time taken for 1 epoch 25.66869854927063 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0259\n",
      "Epoch 34 Batch 50 Loss 0.0282\n",
      "Epoch 34 Loss 0.0275\n",
      "Time taken for 1 epoch 25.664570808410645 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0235\n",
      "Epoch 35 Batch 50 Loss 0.0309\n",
      "Epoch 35 Loss 0.0274\n",
      "Time taken for 1 epoch 25.664278030395508 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0188\n",
      "Epoch 36 Batch 50 Loss 0.0327\n",
      "Epoch 36 Loss 0.0276\n",
      "Time taken for 1 epoch 25.89516520500183 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0231\n",
      "Epoch 37 Batch 50 Loss 0.0297\n",
      "Epoch 37 Loss 0.0274\n",
      "Time taken for 1 epoch 25.58456254005432 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0236\n",
      "Epoch 38 Batch 50 Loss 0.0282\n",
      "Epoch 38 Loss 0.0271\n",
      "Time taken for 1 epoch 25.63637351989746 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0186\n",
      "Epoch 39 Batch 50 Loss 0.0272\n",
      "Epoch 39 Loss 0.0271\n",
      "Time taken for 1 epoch 25.647584915161133 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0212\n",
      "Epoch 40 Batch 50 Loss 0.0274\n",
      "Epoch 40 Loss 0.0272\n",
      "Time taken for 1 epoch 25.869014263153076 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.0192\n",
      "Epoch 41 Batch 50 Loss 0.0256\n",
      "Epoch 41 Loss 0.0270\n",
      "Time taken for 1 epoch 25.68087887763977 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.0200\n",
      "Epoch 42 Batch 50 Loss 0.0311\n",
      "Epoch 42 Loss 0.0270\n",
      "Time taken for 1 epoch 25.669480323791504 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.0233\n",
      "Epoch 43 Batch 50 Loss 0.0291\n",
      "Epoch 43 Loss 0.0268\n",
      "Time taken for 1 epoch 25.679429054260254 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.0193\n",
      "Epoch 44 Batch 50 Loss 0.0273\n",
      "Epoch 44 Loss 0.0267\n",
      "Time taken for 1 epoch 25.950228214263916 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.0198\n",
      "Epoch 45 Batch 50 Loss 0.0278\n",
      "Epoch 45 Loss 0.0270\n",
      "Time taken for 1 epoch 25.687389612197876 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.0214\n",
      "Epoch 46 Batch 50 Loss 0.0317\n",
      "Epoch 46 Loss 0.0269\n",
      "Time taken for 1 epoch 25.712419986724854 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.0226\n",
      "Epoch 47 Batch 50 Loss 0.0269\n",
      "Epoch 47 Loss 0.0268\n",
      "Time taken for 1 epoch 25.67398500442505 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.0221\n",
      "Epoch 48 Batch 50 Loss 0.0320\n",
      "Epoch 48 Loss 0.0271\n",
      "Time taken for 1 epoch 25.92887020111084 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.0223\n",
      "Epoch 49 Batch 50 Loss 0.0268\n",
      "Epoch 49 Loss 0.0265\n",
      "Time taken for 1 epoch 25.739591360092163 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.0218\n",
      "Epoch 50 Batch 50 Loss 0.0288\n",
      "Epoch 50 Loss 0.0266\n",
      "Time taken for 1 epoch 25.736493587493896 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "  # saving (checkpoint) the model every 4 epochs\n",
    "  if (epoch + 1) % 4 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "i1f7yAiKdp10"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result2 = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result2 += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if targ_lang.index_word[predicted_id] == '<end>':\n",
    "      return result2, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result2, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "thjlMbkrdvRg"
   },
   "outputs": [],
   "source": [
    "final_result2 = []\n",
    "\n",
    "def remove_char(s):\n",
    "    remove_result = s[8 : -6]\n",
    "    return remove_result\n",
    "\n",
    "def remove_char_trans(s):\n",
    "    remove_result_trans = s[0 : -6]\n",
    "    return remove_result_trans\n",
    "\n",
    "def translate(sentence):\n",
    "  result2, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "  sent = (remove_char(sentence))\n",
    "  res = (remove_char_trans(result2))\n",
    "  \n",
    "  final_result2.append([sent, res])\n",
    "  df2 = pd.DataFrame(final_result2, columns=['текст', 'перевод с вниманием'])\n",
    "\n",
    "  # print('Input: %s' % (sentence))\n",
    "  # print('Predicted translation: {}'.format(result2))\n",
    "\n",
    "  attention_plot = attention_plot[:len(result2.split(' ')), :len(sentence.split(' '))]\n",
    "  # plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "  return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pyN7MNaGd19P",
    "outputId": "f4eb4f42-312f-48d5-f39b-6b4c2242c764"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7cd76faa50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "-AmBC7KCd7zH",
    "outputId": "07d5abf4-d9f5-4968-af4b-076d94559e3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3b4389f3-c87c-4ed2-bb4b-84365d8030f9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>текст</th>\n",
       "      <th>перевод с вниманием</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>привет !</td>\n",
       "      <td>feasible avoided electrician choice over soup'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>как дела ?</td>\n",
       "      <td>feasible mine terrible woman jeans phoned trap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>как тебя зовут ?</td>\n",
       "      <td>feasible mine terrible woman jeans phoned trap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>что ты делаешь завтра ?</td>\n",
       "      <td>feasible mine choice amateurs model groan lyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>я собираюсь играть в футбол</td>\n",
       "      <td>feasible mine terrible woman jeans phoned trap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>если я смогу , я приду играть</td>\n",
       "      <td>feasible mine terrible woman jeans phoned bana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>когда мы играли в футбол , шел дождь</td>\n",
       "      <td>feasible mine terrible woman jeans reads iphon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>в последнее время я поздно ложусь спать</td>\n",
       "      <td>feasible mine parties zombie duties terrified ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>когда я ехал мимо станции , у меня слетела шляпа</td>\n",
       "      <td>feasible mine parties conspicuous planted croc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ж птица гордая , пока не дадут скорость летать...</td>\n",
       "      <td>pushy lagged stank glasses waits coyote war su...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b4389f3-c87c-4ed2-bb4b-84365d8030f9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3b4389f3-c87c-4ed2-bb4b-84365d8030f9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3b4389f3-c87c-4ed2-bb4b-84365d8030f9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                               текст  \\\n",
       "0                                           привет !   \n",
       "1                                         как дела ?   \n",
       "2                                   как тебя зовут ?   \n",
       "3                            что ты делаешь завтра ?   \n",
       "4                        я собираюсь играть в футбол   \n",
       "5                      если я смогу , я приду играть   \n",
       "6               когда мы играли в футбол , шел дождь   \n",
       "7            в последнее время я поздно ложусь спать   \n",
       "8   когда я ехал мимо станции , у меня слетела шляпа   \n",
       "9  ж птица гордая , пока не дадут скорость летать...   \n",
       "\n",
       "                                 перевод с вниманием  \n",
       "0  feasible avoided electrician choice over soup'...  \n",
       "1  feasible mine terrible woman jeans phoned trap...  \n",
       "2  feasible mine terrible woman jeans phoned trap...  \n",
       "3  feasible mine choice amateurs model groan lyin...  \n",
       "4  feasible mine terrible woman jeans phoned trap...  \n",
       "5  feasible mine terrible woman jeans phoned bana...  \n",
       "6  feasible mine terrible woman jeans reads iphon...  \n",
       "7  feasible mine parties zombie duties terrified ...  \n",
       "8  feasible mine parties conspicuous planted croc...  \n",
       "9  pushy lagged stank glasses waits coyote war su...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Привет!')\n",
    "translate('Как дела?')\n",
    "translate('Как тебя зовут?')\n",
    "translate('Что ты делаешь завтра?')\n",
    "translate('Я собираюсь играть в футбол')\n",
    "translate('Если я смогу, я приду играть')\n",
    "translate('Когда мы играли в футбол, шел дождь')\n",
    "translate('В последнее время я поздно ложусь спать')\n",
    "translate('Когда я ехал мимо станции, у меня слетела шляпа')\n",
    "translate('Ёж птица гордая, пока не дадут скорость - летать не станет')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdhaGeGWoDzG"
   },
   "source": [
    "Очень странный результат получился. Причем лосс у сети с вниманием ниже, чем у сети без внимания. Сеть с вниманием не справилась с задачей, есть признаки зацикленности."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
