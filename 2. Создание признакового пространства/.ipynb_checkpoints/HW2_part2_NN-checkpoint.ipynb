{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_ZPu1YQD7JS",
    "outputId": "13239b5f-cad1-45be-a504-1ad7e1fd81bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-08-10 07:25:04--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:601f:18::a27d:912\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
      "--2022-08-10 07:25:04--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucb470455aeb957ba156507b7823.dl.dropboxusercontent.com/cd/0/inline/Bqstiek9sXUlCBTChsxhDqF-hlVd_O00gK9n-PJTeKtwGQaLDqgbGHtriJTH8ZOPRoZSy5GeoSVCCLolBMhqrw1AmkkS_DMQcGN57HBHc555qgqK6FHFLFD0dW0FNpczemfx-Bv1N16lCpFkhWb6GiEn15GiRuEMx4VqMlV6z3NeHQ/file# [following]\n",
      "--2022-08-10 07:25:05--  https://ucb470455aeb957ba156507b7823.dl.dropboxusercontent.com/cd/0/inline/Bqstiek9sXUlCBTChsxhDqF-hlVd_O00gK9n-PJTeKtwGQaLDqgbGHtriJTH8ZOPRoZSy5GeoSVCCLolBMhqrw1AmkkS_DMQcGN57HBHc555qgqK6FHFLFD0dW0FNpczemfx-Bv1N16lCpFkhWb6GiEn15GiRuEMx4VqMlV6z3NeHQ/file\n",
      "Resolving ucb470455aeb957ba156507b7823.dl.dropboxusercontent.com (ucb470455aeb957ba156507b7823.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601d:15::a27d:50f\n",
      "Connecting to ucb470455aeb957ba156507b7823.dl.dropboxusercontent.com (ucb470455aeb957ba156507b7823.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26233379 (25M) [text/plain]\n",
      "Saving to: ‘positive.csv’\n",
      "\n",
      "positive.csv        100%[===================>]  25.02M  66.1MB/s    in 0.4s    \n",
      "\n",
      "2022-08-10 07:25:05 (66.1 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
      "\n",
      "--2022-08-10 07:25:05--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:601f:18::a27d:912\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
      "--2022-08-10 07:25:06--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc06ee342ac33f27f9c592f995e0.dl.dropboxusercontent.com/cd/0/inline/BqsAMBxGPBFKrXhMZY5w44v7MN6aIUINAoKqAWYAHdLckFfCpVbUECzMjZgjRFapLWb21h_lZCYP6BkhGmFnpFqa7ELDfb03aLDQ5i1KEtkbD6Dbwn08ztCda80Orf6kA8NdgPYt3kkb0B0xPVBP9MXVSFE3O5I5r7FPimCOWRBlPw/file# [following]\n",
      "--2022-08-10 07:25:06--  https://uc06ee342ac33f27f9c592f995e0.dl.dropboxusercontent.com/cd/0/inline/BqsAMBxGPBFKrXhMZY5w44v7MN6aIUINAoKqAWYAHdLckFfCpVbUECzMjZgjRFapLWb21h_lZCYP6BkhGmFnpFqa7ELDfb03aLDQ5i1KEtkbD6Dbwn08ztCda80Orf6kA8NdgPYt3kkb0B0xPVBP9MXVSFE3O5I5r7FPimCOWRBlPw/file\n",
      "Resolving uc06ee342ac33f27f9c592f995e0.dl.dropboxusercontent.com (uc06ee342ac33f27f9c592f995e0.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
      "Connecting to uc06ee342ac33f27f9c592f995e0.dl.dropboxusercontent.com (uc06ee342ac33f27f9c592f995e0.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24450101 (23M) [text/plain]\n",
      "Saving to: ‘negative.csv’\n",
      "\n",
      "negative.csv        100%[===================>]  23.32M  90.9MB/s    in 0.3s    \n",
      "\n",
      "2022-08-10 07:25:06 (90.9 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BiFr7B7aEKeA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nLd0pphfERWD"
   },
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3Yg0Qvb7ET5E"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wp4QmuFfGCh1"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cIQPWwEbEZQ3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Conv1D, GRU, LSTM, Dropout, Flatten\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "psX2cGOFEg-8"
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gnQUQu4qGeBs"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.batch(16)\n",
    "valid_data = valid_data.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "STlCPRlVGmHh"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-FtFoOGVGpt3"
   },
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    \n",
    "    return input_data\n",
    "\n",
    "vocab_size = 10000\n",
    "seq_len = 100\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_len)\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_data = train_data.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glUfX0RbsUV0"
   },
   "source": [
    "Составим нейросеть.\n",
    "\n",
    "Эксперимент показал, насколько важен слой эмбеддинга - просто на плотных слоях метрика accuracy была около 50%. Учитывая, что у нас практически нет дисбаланса классов - это просто случайное гадание. И сеть совершенно не обучалась и не сдвигалась с этих значений.\n",
    "\n",
    "С слоем эмбеддинга количество весов существенно увеличилось, но сеть начала работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L558BcaLHEzp"
   },
   "outputs": [],
   "source": [
    "embedding_dim=200\n",
    "\n",
    "model = Sequential([\n",
    "    vectorize_layer,\n",
    "    Embedding(vocab_size, embedding_dim),\n",
    "    Flatten(),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dropout(.2),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XaD_3PZKH7AZ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8BDCqfXMRG0",
    "outputId": "5f6b79f7-5531-4f6c-ef8f-21ff0c524dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 200)          2000000   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              20001000  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,502,001\n",
      "Trainable params: 22,502,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XNYud2LrIAZC",
    "outputId": "ac958e50-7376-4d32-8c99-a7850cee0e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10633/10633 [==============================] - 101s 9ms/step - loss: 0.3732 - accuracy: 0.8035 - val_loss: 0.3421 - val_accuracy: 0.8255\n",
      "Epoch 2/5\n",
      "10633/10633 [==============================] - 100s 9ms/step - loss: 0.2994 - accuracy: 0.8501 - val_loss: 0.3517 - val_accuracy: 0.8254\n",
      "Epoch 3/5\n",
      "10633/10633 [==============================] - 96s 9ms/step - loss: 0.2406 - accuracy: 0.8851 - val_loss: 0.4408 - val_accuracy: 0.8109\n",
      "Epoch 4/5\n",
      "10633/10633 [==============================] - 95s 9ms/step - loss: 0.1909 - accuracy: 0.9118 - val_loss: 0.5269 - val_accuracy: 0.8084\n",
      "Epoch 5/5\n",
      "10633/10633 [==============================] - 97s 9ms/step - loss: 0.1534 - accuracy: 0.9301 - val_loss: 0.6202 - val_accuracy: 0.8027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e9c4005d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, validation_data=valid_data, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt8zNy2wrFrU"
   },
   "source": [
    "Как видно, после первой же эпохи модель начинает переобучаться. С текстами у меня постоянно такое бывало. \n",
    "\n",
    "Причем дропаут не помогает избавиться от переобучения, а лишь замедляет темп переобучения.\n",
    "\n",
    "Поэтому обучим модель еще раз на одной эпохе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4YVuvuirmyu",
    "outputId": "ac451a2a-5213-4bac-d069-42ac24bb6386"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10633/10633 [==============================] - 96s 9ms/step - loss: 0.3737 - accuracy: 0.8036 - val_loss: 0.3431 - val_accuracy: 0.8266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e963a8f50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    vectorize_layer,\n",
    "    Embedding(vocab_size, embedding_dim),\n",
    "    Flatten(),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dropout(.2),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, validation_data=valid_data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Er8Ho1WW2wI",
    "outputId": "7fe3d9a5-01fd-44ce-c977-ef41e91d6ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82     27731\n",
      "           1       0.83      0.83      0.83     28978\n",
      "\n",
      "    accuracy                           0.83     56709\n",
      "   macro avg       0.83      0.83      0.83     56709\n",
      "weighted avg       0.83      0.83      0.83     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = np.where(pred >= 0.5, 1, 0)\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErBNIw3Xtc7i"
   },
   "source": [
    "Как видно, сеть работает, но очень отстает от логистической регрессии по мешку слов. Видимо, сеть очень простая :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HW2_part2_NN.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
