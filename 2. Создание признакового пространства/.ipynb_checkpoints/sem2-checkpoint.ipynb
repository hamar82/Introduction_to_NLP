{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUotKHRULVPD"
   },
   "source": [
    "# Инструменты для работы с языком "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ba5Z02VLVPK"
   },
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2zHB70n5LVPN",
    "outputId": "76e9cc41-c912-464c-a06e-e02879e69c08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J5YiZNCPLVPe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DFLtXAZ-LVPq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marat\\AppData\\Local\\Temp\\ipykernel_2452\\3125191635.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = positive.append(negative)\n"
     ]
    }
   ],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "j1AEISlBLVP0",
    "outputId": "443eadf2-9df4-4507-f2a5-a64f7968182f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZWta7oDgLVP8"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAapBC7VLVQC"
   },
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "M-AvVt8XLVQD"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSuoVoxcLVQI"
   },
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zeNA7732LVQJ"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeApDOmrLVQN",
    "outputId": "d8c763fe-2658-47ac-fcee-5b7bbe49f0d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPAS0fS-LVQQ",
    "outputId": "aa3ae031-c661-4639-b7ab-f93ba1b6cee5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d77jmVPhLVQU",
    "outputId": "c8de801b-8efc-437e-8673-4e9e31665ea5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xXTBrGELVQX",
    "outputId": "f5b423d9-db6b-4efa-8bfa-a446a55ee018"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHGJBEm-LVQb"
   },
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "eMqZFBTgLVQb"
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZkpqVtILVQe"
   },
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWRtOSzKLVQf",
    "outputId": "668857b0-def2-4547-8fd5-014fe3858bec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('тока', 222044),\n",
       " ('что', 237404),\n",
       " ('видел', 111985),\n",
       " ('рекламу', 202964),\n",
       " ('китеката', 145047),\n",
       " ('по', 183479),\n",
       " ('тв', 220192),\n",
       " ('этим', 241366),\n",
       " ('летом', 152392),\n",
       " ('доставило', 127807)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkmX3iBbLVQi",
    "outputId": "5bbb432e-1c45-422a-edc2-60841ef0ee33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJ8q5_59LVQm",
    "outputId": "d88c6de2-640a-4cc9-ae95-29fe12c80131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.76      0.76     28489\n",
      "    positive       0.76      0.77      0.77     28220\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAhgaYgqLVQp"
   },
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPWXlh6ALVQq",
    "outputId": "094a7189-bc36-42df-81ee-f599a206ca0c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.72      0.56     18218\n",
      "    positive       0.82      0.61      0.70     38491\n",
      "\n",
      "    accuracy                           0.65     56709\n",
      "   macro avg       0.64      0.66      0.63     56709\n",
      "weighted avg       0.71      0.65      0.66     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnfyJkzTLVQu"
   },
   "source": [
    "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJABxhalLVQu"
   },
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LJES2s-LVQv"
   },
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "FmEcRD28LVQ0"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWLhMl9xLVQ3",
    "outputId": "054e5662-1c41-42f6-92e4-ce0194317ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.77      0.75     26763\n",
      "    positive       0.78      0.75      0.77     29946\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTODTRnKLVQ6"
   },
   "source": [
    "В этот раз получилось хуже :( Вернёмся к `CountVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8v9Scpn9Y0M"
   },
   "source": [
    "## PMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVRqLcSY0etj"
   },
   "source": [
    "Можно оценить взаимосвязь слов в корпусе и понять, какие биграммы наиболее часто встречаются в тексте. Для этого можно использовать метрику PMI (Pointwise Mutual Information) - поточечная взаимная информация. Метрика PMI для двух слов вычисляется по формуле:\n",
    "\n",
    "$$pmi(x; y) = log \\frac{p(x,y)}{p(x)p(y)} $$\n",
    "\n",
    "Здесь p(y|x) - вероятность встретить слово $y$ после $x$, $p(y)$ - вероятность встретить слово $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXgDwf6W6Kk5"
   },
   "source": [
    "Оценим важность биграмм в нашем обучающем корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LKmiOEaW53F9",
    "outputId": "96a85968-e0cb-4b17-cd62-bc3de5e3e9b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     C:\\Users\\Marat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\genesis.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      "[('+Никита', '=полностью'), ('+СОННО', '+НЕ'), ('+погода', 'крутая='), (',4', 'запирайте'), (',Дела', 'рез'), ('-/////', 'прбрм-прбрм'), ('-10,11', 'болсо'), ('-163', '-КРАСНЫЙ'), ('-165', '-СИНИЙ'), ('-800', 'нахууй'), ('-АХАХАХАХ', 'ЮБКУ'), ('-Айгуль', 'Маратовна'), ('-Алина', '-Синие'), ('-Аха', 'спетросянил'), ('-Без', 'презерватива'), ('-ВАХАХАХА', 'СТИПЕНДИЯ'), ('-ВСЕМ', 'СПОКОЙНЫХ'), ('-Вам', 'завернуть'), ('-Ваша', 'стиральная'), ('-Весело', 'кншн:3'), ('-Выздоравливай', 'педрилк'), ('-Д-Д-Д-Д-Д-Д-ДРОП', 'ЗЭ'), ('-ДЕТЕЙ', 'НАКРЫЛО'), ('-Домашка', '-кл.час'), ('-Защитано', '-ес'), ('-КРАСНЫЙ', '-ЧЕРНЫЕ'), ('-Керем', 'севгили'), ('-Мамаааа', 'поправь'), ('-НАЧИНАЕТ', 'БЕСИТЬ'), ('-ОЗВУЧИВАТЕЛЬ', 'МУЛЬТИКОВ'), ('-ОНИ', 'СТОЯТ'), ('-Плохое', 'пищеварение'), ('-Поэзия', 'заключает'), ('-ПриФетиГг', 'СолНыСко='), ('-Рыбу', 'соленую'), ('-СИНИЙ', '-БЕЛЫЕ'), ('-СУКА', 'ЛУКАШИН'), ('-Серые', '-НЕМЕЦКИЕ'), ('-Смотрела', 'японскую'), ('-Танцы', '-Хорошие'), ('-Ти', 'кантужена'), ('-Тиць', 'дурне'), ('-Филл', '-познакомились'), ('-ШАПКА', '-ФОН'), ('-Школа', '-Плохие'), ('-Я.банан', '-ахх'), ('-аас', 'бусдыг'), ('-бляя', 'хммммммм'), ('-возвышенная', 'местность'), ('-г', 'үзээ'), ('-гoop', 'Хакүхо'), ('-говорит', 'одноногий'), ('-дак', 'Бася'), ('-дерьмо', 'редкосное'), ('-дирекшионер', '-one'), ('-иногда', '.Ностальгирую'), ('-киллджой', '-шатенка'), ('-классный', 'фильм.правда'), ('-кошка', '-зеленые'), ('-крутенько', '-выйду'), ('-купи', 'куру'), ('-кучи', 'мутики'), ('-ложусь', 'спать-темно'), ('-мега', 'шизофреничная'), ('-место', '-кровать'), ('-напиши', '-нит'), ('-наш', 'класс^^'), ('-опять', 'достаешь'), ('-патлатые', '-лысый'), ('-пиздишь', '-отвечаю'), ('-пиши', 'Ненси'), ('-попробуй', 'помедитировать'), ('-посмотри', 'внимательней'), ('-раз', 'плёткой'), ('-распускаю', 'волосы-'), ('-розовое', 'Нарри'), ('-случайные', 'вопросы-'), ('-спрашивает', 'жена.-У'), ('-столько', 'бабосов'), ('-удивительная', 'штука.Его'), ('-указуказуказуказуа', '-материшся'), ('-умильного', 'львенка'), ('-хаски', '-розовое'), ('-хор', '-найл'), ('-хуи', 'сосешь'), ('-цвета', 'Магнита'), ('-цытата', 'Шимы'), ('-черные', '-аниме'), ('-шапку', '-фон'), ('-ыг', 'үгүйсгэж'), ('-эртага', 'бозорга'), ('-ээр', 'сувгаар'), ('-юн', '-юп'), ('-юп', '-шапку'), ('-языком', 'владеешь'), ('.NET', 'языки.'), ('.Прозвучало', 'неубедительно.Учитель'), ('.Суудлынхаа', 'даруулгыг'), ('.Хочу', 'миксануть'), ('.ШТА', 'БУДИШЬ')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import collocations \n",
    "nltk.download('genesis')\n",
    "\n",
    "print(type(nltk.corpus.genesis.words('english-web.txt')))\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "# bigram_finder.apply_freq_filter(5)\n",
    "bigram_finder = collocations.BigramCollocationFinder.from_documents([nltk.word_tokenize(x) for x in x_train])\n",
    "bigrams = bigram_finder.nbest(bigram_measures.pmi, 100)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_h4Cq1PUTTc-"
   },
   "source": [
    "Можно рассмотреть другие метрики оценки важности биграмм, например, метрику правдоподобия (подробнее про вычисление метрики можно посмотреть [здесь (пункт 5.3.4)](http://www.corpus.unam.mx/cursoenah/ManningSchutze_1999_FoundationsofStatisticalNaturalLanguageProcessing.pdf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lTOJg4KoOo84",
    "outputId": "45d38953-84e0-4a65-fccd-1e96fd83c3f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(', '('), ('RT', '@'), (')', ')'), ('http', ':'), ('!', '!'), (':', 'D'), ('у', 'меня'), (':', '('), (',', 'а'), (',', 'что'), (',', 'но'), (')', 'http'), ('*', '*'), ('у', 'нас'), (':', ')'), ('(', ','), ('не', 'могу'), (',', '('), (':', '-'), (',', ')'), ('?', '?'), (')', ','), (',', ':'), ('@', '('), (',', ','), ('(', ':'), (':', ','), ('&', 'lt'), ('@', ','), ('со', 'мной'), ('@', ':'), ('gt', ';'), ('(', '@'), (';', ')'), (':', ':'), ('новый', 'год'), (')', ':'), (':', '*'), ('не', 'знаю'), (',', '@'), ('@', '@'), ('а', 'я'), ('У', 'меня'), ('потому', 'что'), (',', 'когда'), ('сих', 'пор'), ('lt', ';'), ('&', 'gt'), ('у', 'тебя'), ('все', 'равно'), (';', '('), ('с', 'тобой'), (',', 'как'), ('в', 'школу'), ('&', 'amp'), ('(', 'http'), ('ничего', 'не'), (',', 'я'), ('Доброе', 'утро'), (')', '@'), ('Как', 'же'), ('-', ')'), ('я', 'не'), (':', 'DD'), ('не', '('), ('самом', 'деле'), ('amp', ';'), (',', 'чтобы'), ('как', 'же'), ('не', ')'), ('до', 'сих'), ('(', '!'), ('об', 'этом'), (',', '!'), ('что', 'я'), ('D', 'http'), ('не', ':'), ('.', 'А'), ('никто', 'не'), ('=', ')'), (':', '!'), ('!', ','), ('с', 'кем'), (':', '|'), ('?', '—'), ('никогда', 'не'), ('а', 'потом'), ('--', '--'), ('и', ')'), (',', '.'), ('.', ','), ('не', '@'), ('@', 'не'), ('.', 'Но'), ('#', 'євромайдан'), ('с', 'ним'), ('“', '@'), ('@', '!'), (':', '.'), ('в', 'этом')]\n"
     ]
    }
   ],
   "source": [
    "bigrams = bigram_finder.nbest(bigram_measures.likelihood_ratio, 100)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfjCYZa8TeX_"
   },
   "source": [
    "Как можно заметить, немаловажную роль в текстах занимает пунктуация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AJk1B39LVRP"
   },
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpWhsTuRLVRP",
    "outputId": "1cd18efe-a3cd-4f56-ec4c-bec8b6ee442e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Marat\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OdRF7rlyLVRS",
    "outputId": "dd4ce4f0-13d0-4b21-a3a1-b9ecb281894f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "OfXiH98XLVRV"
   },
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtiIhHDMLVRY"
   },
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZnbarm_LVRY",
    "outputId": "88f40278-165a-46ad-a75e-2e5d8e7e3a4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.76      0.78     29292\n",
      "    positive       0.76      0.80      0.78     27417\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('punkt')\n",
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wr934O7yLVRb"
   },
   "source": [
    "Получилось чууть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7O_oD1fLVRc"
   },
   "source": [
    "## Лемматизация\n",
    "\n",
    "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96HdoB7zLVRc",
    "outputId": "987397bc-55cb-4830-c361-5568f1f2e015"
   },
   "outputs": [],
   "source": [
    "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!cp mystem /bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzQwGwAaZWV5"
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_w-_fkNtLVRf"
   },
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjHHLQv9txDq",
    "outputId": "35bcb3cc-7853-48bf-d38d-04157f45221d"
   },
   "outputs": [],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI1eftjkLVRi"
   },
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j4MLqlZnxNEj",
    "outputId": "ffb676bb-932e-4579-817a-c15616431521"
   },
   "outputs": [],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADcGtz4JLVRl"
   },
   "source": [
    "Давайте терепь используем лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x48Q56tiLVRn"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def my_preproc(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEwOQTJPLVRq",
    "outputId": "b1047a05-9fa7-4994-c947-578cfc4d9825"
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJlvqWuALVRs"
   },
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый и с кучей функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHDkurN1zf7g",
    "outputId": "c9934446-bf72-4603-8a51-9f6ebf406e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pymorphy2\n",
      "  Using cached pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "Collecting dawg-python>=0.7.1\n",
      "  Using cached DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Collecting docopt>=0.6\n",
      "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
      "  Using cached pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "Installing collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script pymorphy.exe is installed in 'C:\\Users\\Marat\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qaz0x7frLVRw"
   },
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdf6XoEbLVRw",
    "outputId": "a1984e06-dbeb-4377-896d-b7014b6b84c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2472, 10),))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0KuHQGPgLVRz",
    "outputId": "3cdbe79d-ec3f-4a07-ff3a-52e8810face1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gg0EASPcLVR8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFTkF8xUARlS"
   },
   "source": [
    "### [Natasha](https://github.com/natasha/)\n",
    "\n",
    "В библиотеке natasha реализовано множество полезных библиотек для русского языка: разбиение на токены и предложения, русскоязычные word embeddings, морфологический, синтаксический анализ, лемматизация, извлечение именованных сущностей и т.д. Модуль библиотеки Razdel, основанный на правилах, предназначен для разбиения текста на токены и предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CVeDxeIA6rg",
    "outputId": "ff583009-ae7a-4b68-b6a7-ca1ba48c0732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting razdel\n",
      "  Using cached razdel-0.5.0-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: razdel\n",
      "Successfully installed razdel-0.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script razdel-ctl.exe is installed in 'C:\\Users\\Marat\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOTkw9MpAnNN",
    "outputId": "51fc6e54-3b82-4c1c-91c2-5b6a60f6304f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 13, 'Кружка-термос'),\n",
       " Substring(14, 16, 'на'),\n",
       " Substring(17, 20, '0.5'),\n",
       " Substring(20, 21, 'л'),\n",
       " Substring(22, 23, '('),\n",
       " Substring(23, 28, '50/64'),\n",
       " Substring(29, 32, 'см³'),\n",
       " Substring(32, 33, ','),\n",
       " Substring(34, 37, '516'),\n",
       " Substring(37, 38, ';'),\n",
       " Substring(38, 41, '...'),\n",
       " Substring(41, 42, ')')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "\n",
    "tokens = list(tokenize('Кружка-термос на 0.5л (50/64 см³, 516;...)'))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ftx-WzUbBCpO",
    "outputId": "40c67fa4-fab6-4c1b-f651-06951a38798e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Кружка-термос',\n",
       " 'на',\n",
       " '0.5',\n",
       " 'л',\n",
       " '(',\n",
       " '50/64',\n",
       " 'см³',\n",
       " ',',\n",
       " '516',\n",
       " ';',\n",
       " '...',\n",
       " ')']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uyhsQp4MGbW8",
    "outputId": "55f84576-aaad-4a68-c5d9-38dc0ea2f721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting natasha\n",
      "  Downloading natasha-1.5.0-py3-none-any.whl (34.4 MB)\n",
      "     ---------------------------------------- 34.4/34.4 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting navec>=0.9.0\n",
      "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: razdel>=0.5.0 in c:\\users\\marat\\appdata\\roaming\\python\\python39\\site-packages (from natasha) (0.5.0)\n",
      "Collecting ipymarkup>=0.8.0\n",
      "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
      "Collecting yargy>=0.14.0\n",
      "  Downloading yargy-0.15.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\marat\\appdata\\roaming\\python\\python39\\site-packages (from natasha) (0.9.1)\n",
      "Collecting slovnet>=0.6.0\n",
      "  Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
      "     -------------------------------------- 46.7/46.7 kB 387.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: intervaltree>=3 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from navec>=0.9.0->natasha) (1.21.5)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\marat\\appdata\\roaming\\python\\python39\\site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\marat\\appdata\\roaming\\python\\python39\\site-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\marat\\appdata\\roaming\\python\\python39\\site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
      "Installing collected packages: navec, yargy, slovnet, ipymarkup, natasha\n",
      "Successfully installed ipymarkup-0.9.0 natasha-1.5.0 navec-0.10.0 slovnet-0.6.0 yargy-0.15.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script navec-train.exe is installed in 'C:\\Users\\Marat\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMO3jsqLKSIV"
   },
   "source": [
    "С помощью библиотеки natasha можно также лемматизировать тексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "vJZgfRnvIS2q"
   },
   "outputs": [],
   "source": [
    "from natasha import Doc, MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "def natasha_lemmatize(text):\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter)\n",
    "    doc.tag_morph(morph_tagger)\n",
    "    for token in doc.tokens:\n",
    "        token.lemmatize(morph_vocab)\n",
    "    return {_.text: _.lemma for _ in doc.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBtlnYlFBOKv",
    "outputId": "47a9e7d6-7f03-4e93-e57c-84dce5657d97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Посол': 'посол',\n",
       " 'Израиля': 'израиль',\n",
       " 'на': 'на',\n",
       " 'Украине': 'украина',\n",
       " 'Йоэль': 'йоэль',\n",
       " 'Лион': 'лион',\n",
       " 'признался': 'признаться',\n",
       " ',': ',',\n",
       " 'что': 'что',\n",
       " 'пришел': 'прийти',\n",
       " 'в': 'в',\n",
       " 'шок': 'шок',\n",
       " 'узнав': 'узнать',\n",
       " 'о': 'о',\n",
       " 'решении': 'решение',\n",
       " 'властей': 'власть',\n",
       " 'Львовской': 'львовский',\n",
       " 'области': 'область',\n",
       " 'объявить': 'объявить',\n",
       " '2019': '2019',\n",
       " 'год': 'год',\n",
       " 'годом': 'год',\n",
       " 'лидера': 'лидер',\n",
       " 'запрещенной': 'запретить',\n",
       " 'России': 'россия',\n",
       " 'Организации': 'организация',\n",
       " 'украинских': 'украинский',\n",
       " 'националистов': 'националист',\n",
       " '(': '(',\n",
       " 'ОУН': 'оун',\n",
       " ')': ')',\n",
       " 'Степана': 'степан',\n",
       " 'Бандеры': 'бандера',\n",
       " '.': '.',\n",
       " 'Свое': 'свой',\n",
       " 'заявление': 'заявление',\n",
       " 'он': 'он',\n",
       " 'разместил': 'разместить',\n",
       " 'Twitter': 'twitter',\n",
       " '«': '«',\n",
       " 'Я': 'я',\n",
       " 'не': 'не',\n",
       " 'могу': 'мочь',\n",
       " 'понять': 'понять',\n",
       " 'как': 'как',\n",
       " 'прославление': 'прославление',\n",
       " 'тех': 'тот',\n",
       " 'кто': 'кто',\n",
       " 'непосредственно': 'непосредственно',\n",
       " 'принимал': 'принимать',\n",
       " 'участие': 'участие',\n",
       " 'ужасных': 'ужасный',\n",
       " 'антисемитских': 'антисемитский',\n",
       " 'преступлениях': 'преступление',\n",
       " 'помогает': 'помогать',\n",
       " 'бороться': 'бороться',\n",
       " 'с': 'с',\n",
       " 'антисемитизмом': 'антисемитизм',\n",
       " 'и': 'и',\n",
       " 'ксенофобией': 'ксенофобия',\n",
       " 'Украина': 'украина',\n",
       " 'должна': 'должный',\n",
       " 'забывать': 'забывать',\n",
       " 'совершенных': 'совершить',\n",
       " 'против': 'против',\n",
       " 'евреев': 'еврей',\n",
       " 'никоим': 'никой',\n",
       " 'образом': 'образ',\n",
       " 'отмечать': 'отмечать',\n",
       " 'их': 'они',\n",
       " 'через': 'через',\n",
       " 'почитание': 'почитание',\n",
       " 'исполнителей': 'исполнитель',\n",
       " '»': '»',\n",
       " '—': '—',\n",
       " 'написал': 'написать',\n",
       " 'дипломат': 'дипломат',\n",
       " '11': '11',\n",
       " 'декабря': 'декабрь',\n",
       " 'Львовский': 'львовский',\n",
       " 'областной': 'областной',\n",
       " 'совет': 'совет',\n",
       " 'принял': 'принять',\n",
       " 'решение': 'решение',\n",
       " 'провозгласить': 'провозгласить',\n",
       " 'регионе': 'регион',\n",
       " 'связи': 'связь',\n",
       " 'празднованием': 'празднование',\n",
       " '110-летия': '110-летие',\n",
       " 'со': 'с',\n",
       " 'дня': 'день',\n",
       " 'рождения': 'рождение',\n",
       " 'Бандера': 'бандера',\n",
       " 'родился': 'родиться',\n",
       " '1': '1',\n",
       " 'января': 'январь',\n",
       " '1909': '1909',\n",
       " 'года': 'год',\n",
       " 'В': 'в',\n",
       " 'июле': 'июль',\n",
       " 'аналогичное': 'аналогичный',\n",
       " 'Житомирский': 'житомирский',\n",
       " 'начале': 'начало',\n",
       " 'месяца': 'месяц',\n",
       " 'предложением': 'предложение',\n",
       " 'к': 'к',\n",
       " 'президенту': 'президент',\n",
       " 'страны': 'страна',\n",
       " 'Петру': 'петр',\n",
       " 'Порошенко': 'порошенко',\n",
       " 'вернуть': 'вернуть',\n",
       " 'Бандере': 'бандера',\n",
       " 'звание': 'звание',\n",
       " 'Героя': 'герой',\n",
       " 'Украины': 'украина',\n",
       " 'обратились': 'обратиться',\n",
       " 'депутаты': 'депутат',\n",
       " 'Верховной': 'верховный',\n",
       " 'Рады': 'рада',\n",
       " 'Парламентарии': 'парламентарий',\n",
       " 'уверены': 'уверить',\n",
       " 'признание': 'признание',\n",
       " 'национальным': 'национальный',\n",
       " 'героем': 'герой',\n",
       " 'поможет': 'помочь',\n",
       " 'борьбе': 'борьба',\n",
       " 'подрывной': 'подрывной',\n",
       " 'деятельностью': 'деятельность',\n",
       " 'информационном': 'информационный',\n",
       " 'поле': 'поле',\n",
       " 'а': 'а',\n",
       " 'также': 'также',\n",
       " 'остановит': 'остановить',\n",
       " 'распространение': 'распространение',\n",
       " 'мифов': 'миф',\n",
       " 'созданных': 'создать',\n",
       " 'российской': 'российский',\n",
       " 'пропагандой': 'пропаганда',\n",
       " 'Степан': 'степан',\n",
       " '1909-1959': '1909-1959',\n",
       " 'был': 'быть',\n",
       " 'одним': 'один',\n",
       " 'из': 'из',\n",
       " 'лидеров': 'лидер',\n",
       " 'выступающей': 'выступать',\n",
       " 'за': 'за',\n",
       " 'создание': 'создание',\n",
       " 'независимого': 'независимый',\n",
       " 'государства': 'государство',\n",
       " 'территориях': 'территория',\n",
       " 'украиноязычным': 'украиноязычный',\n",
       " 'населением': 'население',\n",
       " '2010': '2010',\n",
       " 'году': 'год',\n",
       " 'период': 'период',\n",
       " 'президентства': 'президентство',\n",
       " 'Виктора': 'виктор',\n",
       " 'Ющенко': 'ющенко',\n",
       " 'посмертно': 'посмертно',\n",
       " 'признан': 'признать',\n",
       " 'Героем': 'герой',\n",
       " 'однако': 'однако',\n",
       " 'впоследствии': 'впоследствии',\n",
       " 'это': 'это',\n",
       " 'было': 'быть',\n",
       " 'отменено': 'отменить',\n",
       " 'судом': 'суд'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Посол Израиля на Украине Йоэль Лион признался, что пришел в шок, узнав о решении властей Львовской области объявить 2019 год годом лидера запрещенной в России Организации украинских националистов (ОУН) Степана Бандеры. Свое заявление он разместил в Twitter. «Я не могу понять, как прославление тех, кто непосредственно принимал участие в ужасных антисемитских преступлениях, помогает бороться с антисемитизмом и ксенофобией. Украина не должна забывать о преступлениях, совершенных против украинских евреев, и никоим образом не отмечать их через почитание их исполнителей», — написал дипломат. 11 декабря Львовский областной совет принял решение провозгласить 2019 год в регионе годом Степана Бандеры в связи с празднованием 110-летия со дня рождения лидера ОУН (Бандера родился 1 января 1909 года). В июле аналогичное решение принял Житомирский областной совет. В начале месяца с предложением к президенту страны Петру Порошенко вернуть Бандере звание Героя Украины обратились депутаты Верховной Рады. Парламентарии уверены, что признание Бандеры национальным героем поможет в борьбе с подрывной деятельностью против Украины в информационном поле, а также остановит «распространение мифов, созданных российской пропагандой». Степан Бандера (1909-1959) был одним из лидеров Организации украинских националистов, выступающей за создание независимого государства на территориях с украиноязычным населением. В 2010 году в период президентства Виктора Ющенко Бандера был посмертно признан Героем Украины, однако впоследствии это решение было отменено судом. '\n",
    "\n",
    "natasha_lemmatize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rck5OVqhLVSA"
   },
   "source": [
    "### mystem vs. pymorphy vs. natasha\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту, natasha тоже с этим тоже не справляется успешно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "kH2GQ4ddLVSB"
   },
   "outputs": [],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwF-XsjeI3eX",
    "outputId": "34e9f131-3af5-4a87-9a8c-aa51d6e076ae"
   },
   "outputs": [],
   "source": [
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9jezRVlFmDo",
    "outputId": "e2224fd9-09e3-428e-fa6a-1af94dcb2ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'За': 'за', 'время': 'время', 'обучения': 'обучение', 'я': 'я', 'прослушал': 'прослушать', 'больше': 'большой', 'сорока': 'сорок', 'курсов': 'курс', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "print(natasha_lemmatize(homonym1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXjGBQPoI9gl",
    "outputId": "049fe8af-e0c5-499f-cc10-6d05b047a168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Сорока': 'сорок', 'своровала': 'своровать', 'блестящее': 'блестящий', 'украшение': 'украшение', 'со': 'с', 'стола': 'стол', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "print(natasha_lemmatize(homonym2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP5qFnilLVSI"
   },
   "source": [
    "## Словарь, закон Ципфа и закон Хипса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1umtd3OLVSI"
   },
   "source": [
    "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "lY0cWJ7eLVSJ"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vIjqSVjpLVSL",
    "outputId": "a75ec748-ab21-4bd0-cd41-5a9fa8362b22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "_oWC7NpkLVSO",
    "outputId": "965b9fbd-6328-4c13-f20f-cd3714d1adb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69472),\n",
       " ('и', 55166),\n",
       " ('в', 52902),\n",
       " ('я', 52818),\n",
       " ('RT', 38070),\n",
       " ('на', 35759),\n",
       " ('http', 32998),\n",
       " ('что', 31541),\n",
       " ('с', 27217),\n",
       " ('а', 26860)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "FrPkce0SLVSQ",
    "outputId": "d2ab5675-433a-480a-90ee-fa5dd9890922"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
    "plt.plot(first_100_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_N5V_K-LVSU"
   },
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dw0GieJSMU-O"
   },
   "source": [
    "## Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какой у нас размер словаря:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "QUQ6kAgPMqNn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351123"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_dict_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем просто поделить словарь на 3 части, и на каждой части обучится. Для того, чтобы остальные слова не входили в обучение, поместим их в стоп-слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_freq_tokens = [itm[0] for itm in freq_dict_sorted[:117033]]\n",
    "middle_freq_tokens = [itm[0] for itm in freq_dict_sorted[117033:234066]]\n",
    "low_freq_tokens = [itm[0] for itm in freq_dict_sorted[234066:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.76      0.78     29050\n",
      "    positive       0.76      0.79      0.78     27659\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise + middle_freq_tokens + low_freq_tokens)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.54      0.68     47949\n",
      "    positive       0.23      0.77      0.36      8760\n",
      "\n",
      "    accuracy                           0.58     56709\n",
      "   macro avg       0.58      0.65      0.52     56709\n",
      "weighted avg       0.82      0.58      0.63     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise + high_freq_tokens + low_freq_tokens)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.53      0.68     47917\n",
      "    positive       0.22      0.74      0.34      8792\n",
      "\n",
      "    accuracy                           0.57     56709\n",
      "   macro avg       0.57      0.64      0.51     56709\n",
      "weighted avg       0.81      0.57      0.62     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise + high_freq_tokens + middle_freq_tokens)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, наиболее важными токенами для обучения являются частотные токены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV3fmzp-LVSU"
   },
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "qjkMxK9VLVSV",
    "outputId": "dfea56d5-4d92-4862-9788-29c8c8db29ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27881\n",
      "    positive       1.00      1.00      1.00     28828\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2fRbUAvLVSX"
   },
   "source": [
    "Шок! Стоило оставить пунктуацию -- и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06103635,  0.40106201, -0.02127107, ...,  0.00834416,\n",
       "         0.00569631,  0.00070137]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "b_JRuyuRLVSY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>)</td>\n",
       "      <td>58.241211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43387</th>\n",
       "      <td>d</td>\n",
       "      <td>26.873258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44844</th>\n",
       "      <td>dd</td>\n",
       "      <td>10.415359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29339</th>\n",
       "      <td>^_^</td>\n",
       "      <td>9.263415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44852</th>\n",
       "      <td>ddd</td>\n",
       "      <td>7.903490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-d</td>\n",
       "      <td>7.741717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>*</td>\n",
       "      <td>7.016647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29245</th>\n",
       "      <td>:</td>\n",
       "      <td>6.050693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44854</th>\n",
       "      <td>dddd</td>\n",
       "      <td>4.792312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44855</th>\n",
       "      <td>ddddd</td>\n",
       "      <td>3.237033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44856</th>\n",
       "      <td>dddddd</td>\n",
       "      <td>2.122652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162879</th>\n",
       "      <td>люблю</td>\n",
       "      <td>1.846348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29291</th>\n",
       "      <td>=^_^=</td>\n",
       "      <td>1.810089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227663</th>\n",
       "      <td>спасибо</td>\n",
       "      <td>1.785617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246845</th>\n",
       "      <td>х</td>\n",
       "      <td>1.394665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>%</td>\n",
       "      <td>1.392003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106129</th>\n",
       "      <td>ахах</td>\n",
       "      <td>1.364982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106179</th>\n",
       "      <td>ахахах</td>\n",
       "      <td>1.269905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77802</th>\n",
       "      <td>okirilyuk</td>\n",
       "      <td>1.261364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206692</th>\n",
       "      <td>приятно</td>\n",
       "      <td>1.170058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature name  importance\n",
       "8                 )   58.241211\n",
       "43387             d   26.873258\n",
       "44844            dd   10.415359\n",
       "29339           ^_^    9.263415\n",
       "44852           ddd    7.903490\n",
       "250              -d    7.741717\n",
       "9                 *    7.016647\n",
       "29245             :    6.050693\n",
       "44854          dddd    4.792312\n",
       "44855         ddddd    3.237033\n",
       "44856        dddddd    2.122652\n",
       "162879        люблю    1.846348\n",
       "29291         =^_^=    1.810089\n",
       "227663      спасибо    1.785617\n",
       "246845            х    1.394665\n",
       "3                 %    1.392003\n",
       "106129         ахах    1.364982\n",
       "106179       ахахах    1.269905\n",
       "77802     okirilyuk    1.261364\n",
       "206692      приятно    1.170058"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_important_positive = pd.DataFrame(zip(vec.get_feature_names(), clf.coef_[0]), columns=['feature name', 'importance']).sort_values(by='importance', ascending=False).head(20)\n",
    "feats_important_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(</td>\n",
       "      <td>-59.818515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101282</th>\n",
       "      <td>|</td>\n",
       "      <td>-11.396520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179788</th>\n",
       "      <td>о_о</td>\n",
       "      <td>-10.709667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-/</td>\n",
       "      <td>-8.740793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77426</th>\n",
       "      <td>o_o</td>\n",
       "      <td>-8.447268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42310</th>\n",
       "      <td>cio_optimal</td>\n",
       "      <td>-5.381760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92647</th>\n",
       "      <td>to_over_kill</td>\n",
       "      <td>-5.351668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46650</th>\n",
       "      <td>do_or_die_xxx</td>\n",
       "      <td>-4.710747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81689</th>\n",
       "      <td>prisonero_o</td>\n",
       "      <td>-4.151170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84336</th>\n",
       "      <td>rt</td>\n",
       "      <td>-4.096323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83331</th>\n",
       "      <td>reno_oppa</td>\n",
       "      <td>-3.676747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54954</th>\n",
       "      <td>horanso_on</td>\n",
       "      <td>-3.602871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62683</th>\n",
       "      <td>kota_oo_oo</td>\n",
       "      <td>-3.122619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82609</th>\n",
       "      <td>radio_of_moon</td>\n",
       "      <td>-2.807735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29983</th>\n",
       "      <td>_do_or_die__</td>\n",
       "      <td>-2.692158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40148</th>\n",
       "      <td>boo_ohoo</td>\n",
       "      <td>-2.615891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77433</th>\n",
       "      <td>o_obnulyay</td>\n",
       "      <td>-2.510438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224966</th>\n",
       "      <td>снаступающимтвиттерский</td>\n",
       "      <td>-2.420769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58974</th>\n",
       "      <td>july_to_october</td>\n",
       "      <td>-2.405182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67604</th>\n",
       "      <td>lponomarenko_o</td>\n",
       "      <td>-2.397093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature name  importance\n",
       "7                             (  -59.818515\n",
       "101282                        |  -11.396520\n",
       "179788                      о_о  -10.709667\n",
       "136                          -/   -8.740793\n",
       "77426                       o_o   -8.447268\n",
       "42310               cio_optimal   -5.381760\n",
       "92647              to_over_kill   -5.351668\n",
       "46650             do_or_die_xxx   -4.710747\n",
       "81689               prisonero_o   -4.151170\n",
       "84336                        rt   -4.096323\n",
       "83331                 reno_oppa   -3.676747\n",
       "54954                horanso_on   -3.602871\n",
       "62683                kota_oo_oo   -3.122619\n",
       "82609             radio_of_moon   -2.807735\n",
       "29983              _do_or_die__   -2.692158\n",
       "40148                  boo_ohoo   -2.615891\n",
       "77433                o_obnulyay   -2.510438\n",
       "224966  снаступающимтвиттерский   -2.420769\n",
       "58974           july_to_october   -2.405182\n",
       "67604            lponomarenko_o   -2.397093"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_important_negative = pd.DataFrame(zip(vec.get_feature_names(), clf.coef_[0]), columns=['feature name', 'importance']).sort_values(by='importance', ascending=True).head(20)\n",
    "feats_important_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, самыми значимыми фичами для отнесения твита к позитивному или негативному являются смайлики ')' и '('"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vtAyItvLVSb"
   },
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "uqH07o-7LVSc",
    "outputId": "fad0a24a-98ee-4f84-8782-495548eb0fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     32783\n",
      "    positive       0.83      1.00      0.91     23926\n",
      "\n",
      "    accuracy                           0.91     56709\n",
      "   macro avg       0.92      0.93      0.91     56709\n",
      "weighted avg       0.93      0.91      0.92     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = ')'\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5THCOjMLVSg"
   },
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "AIUwDOabLVSh",
    "outputId": "54f129b1-994f-448e-e861-1912b4a21cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99     27818\n",
      "    positive       1.00      0.99      0.99     28891\n",
      "\n",
      "    accuracy                           0.99     56709\n",
      "   macro avg       0.99      0.99      0.99     56709\n",
      "weighted avg       0.99      0.99      0.99     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_E0uPpgLVSj"
   },
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы решительно рулят.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание\n",
    "\n",
    "все материалы для выполения дз в `sem2.ipynb`\n",
    "\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27929\n",
      "    positive       1.00      1.00      1.00     28780\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer\n",
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27881\n",
      "    positive       1.00      1.00      1.00     28828\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TfidfVectorizer\n",
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95     27661\n",
      "    positive       0.96      0.95      0.96     29048\n",
      "\n",
      "    accuracy                           0.96     56709\n",
      "   macro avg       0.96      0.96      0.96     56709\n",
      "weighted avg       0.96      0.96      0.96     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HashingVectorizer, n_features=100\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vec = HashingVectorizer(n_features=100, ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.93     27544\n",
      "    positive       0.94      0.93      0.94     29165\n",
      "\n",
      "    accuracy                           0.94     56709\n",
      "   macro avg       0.94      0.94      0.94     56709\n",
      "weighted avg       0.94      0.94      0.94     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HashingVectorizer, n_features=50\n",
    "vec = HashingVectorizer(n_features=50, ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.98      0.98     27816\n",
      "    positive       0.98      0.98      0.98     28893\n",
      "\n",
      "    accuracy                           0.98     56709\n",
      "   macro avg       0.98      0.98      0.98     56709\n",
      "weighted avg       0.98      0.98      0.98     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HashingVectorizer, n_features=200\n",
    "vec = HashingVectorizer(n_features=200, ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту работу выполнил на локальной машине, а часть с нейросетью сделал в коллабе: \n",
    "https://colab.research.google.com/drive/1QxgHjLHcC195FHFyC5uexTyhO4JdWMWH?usp=sharing\n",
    "\n",
    "Также можно посмотреть второй файл с именем HW2_part2_NN.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "- CountVectorizer и TfidfVectorizer без обрезания пунктуации имеют лучшие результаты\n",
    "- HashingVectorizer имеет чуть худший результат.\n",
    "- Хуже всего справилась нейросеть - 82%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gJABxhalLVQu",
    "IaQMCGHFLVQ6",
    "5AJk1B39LVRP",
    "RJlvqWuALVRs",
    "rck5OVqhLVSA",
    "mV3fmzp-LVSU",
    "H5THCOjMLVSg",
    "02s2Vh7MLVSj",
    "b1khxRFDLVSm",
    "sfUmWcAQLVSt",
    "BxvtN-3zLVS5",
    "gyrHhYkgLVTB"
   ],
   "name": "sem1_intro_common.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
