{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y_ZPu1YQD7JS",
    "outputId": "13239b5f-cad1-45be-a504-1ad7e1fd81bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BiFr7B7aEKeA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nLd0pphfERWD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marat\\AppData\\Local\\Temp\\ipykernel_5132\\3125191635.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = positive.append(negative)\n"
     ]
    }
   ],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3Yg0Qvb7ET5E"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Wp4QmuFfGCh1"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cIQPWwEbEZQ3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Conv1D, GRU, LSTM, Dropout, Flatten\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "psX2cGOFEg-8"
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gnQUQu4qGeBs"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.batch(16)\n",
    "valid_data = valid_data.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "STlCPRlVGmHh"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-FtFoOGVGpt3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Marat\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "def custom_standardization(input_data):\n",
    "    \n",
    "    return input_data\n",
    "\n",
    "vocab_size = 10000\n",
    "seq_len = 100\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_len)\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_data = train_data.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glUfX0RbsUV0"
   },
   "source": [
    "Составим нейросеть.\n",
    "\n",
    "Эксперимент показал, насколько важен слой эмбеддинга - просто на плотных слоях метрика accuracy была около 50%. Учитывая, что у нас практически нет дисбаланса классов - это просто случайное гадание. И сеть совершенно не обучалась и не сдвигалась с этих значений.\n",
    "\n",
    "С слоем эмбеддинга количество весов существенно увеличилось, но сеть начала работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "L558BcaLHEzp"
   },
   "outputs": [],
   "source": [
    "embedding_dim=200\n",
    "\n",
    "model = Sequential([\n",
    "    vectorize_layer,\n",
    "    Embedding(vocab_size, embedding_dim),\n",
    "    Flatten(),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dropout(.2),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XaD_3PZKH7AZ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8BDCqfXMRG0",
    "outputId": "5f6b79f7-5531-4f6c-ef8f-21ff0c524dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 200)          2000000   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              20001000  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 500)               500500    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 501       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,502,001\n",
      "Trainable params: 22,502,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XNYud2LrIAZC",
    "outputId": "ac958e50-7376-4d32-8c99-a7850cee0e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marat\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\backend.py:5676: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10633/10633 [==============================] - 18410s 2s/step - loss: 0.3729 - accuracy: 0.8045 - val_loss: 0.3347 - val_accuracy: 0.8279\n",
      "Epoch 2/5\n",
      " 8636/10633 [=======================>......] - ETA: 53:06 - loss: 0.2991 - accuracy: 0.8507"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, validation_data=valid_data, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt8zNy2wrFrU"
   },
   "source": [
    "Как видно, после первой же эпохи модель начинает переобучаться.\n",
    "\n",
    "Причем дропаут не помогает избавиться от переобучения, а лишь замедляет темп переобучения.\n",
    "\n",
    "Поэтому обучим модель еще раз на одной эпохе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w4YVuvuirmyu",
    "outputId": "ac451a2a-5213-4bac-d069-42ac24bb6386"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    vectorize_layer,\n",
    "    Embedding(vocab_size, embedding_dim),\n",
    "    Flatten(),\n",
    "    Dense(1000, activation='relu'),\n",
    "    Dropout(.2),\n",
    "    Dense(500, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, validation_data=valid_data, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Er8Ho1WW2wI",
    "outputId": "7fe3d9a5-01fd-44ce-c977-ef41e91d6ba2"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = np.where(pred >= 0.5, 1, 0)\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErBNIw3Xtc7i"
   },
   "source": [
    "Как видно, сеть работает, но очень отстает от логистической регрессии по мешку слов. Видимо, сеть очень простая :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HW2_part2_NN.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
